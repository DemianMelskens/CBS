{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "from instaloader import Post\n",
    "import pandas as pd\n",
    "import os\n",
    "import instaloader\n",
    "import sys\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions    \n",
    "def outputCSV(dataset, filename):\n",
    "    dataset.to_csv(\"../../data/\" + filename, sep=';')\n",
    "    \n",
    "def cprint(text):\n",
    "    sys.stdout.write(\"\\r\" + text)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datum               22\n",
       "url                 22\n",
       "sentiment            6\n",
       "discussielengte     19\n",
       "views                5\n",
       "auteur              22\n",
       "GPS breedtegraad     2\n",
       "GPS lengtegraad      2\n",
       "bericht tekst       22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve data\n",
    "insta = pd.read_csv('../../data/Coosto_berichten.csv', delimiter=';')\n",
    "\n",
    "# remove empty columns\n",
    "insta = insta.drop(['zoekopdracht', 'type', 'volgers', 'invloed', 'titel', 'type bron'], axis=1)\n",
    "\n",
    "# check with count()\n",
    "insta.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all posts from instagram using an array of urls\n",
    "def get_posts(urls):\n",
    "    posts_dict = {}\n",
    "    total_length = len(urls)\n",
    "    \n",
    "    for index, url in enumerate(urls):\n",
    "        shortcode = url.split(\"/\")[-2]\n",
    "        \n",
    "        try:\n",
    "            L = instaloader.Instaloader()\n",
    "            post = Post.from_shortcode(L.context, url.split(\"/\")[-2])\n",
    "            posts_dict[shortcode] = post\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        cprint(\"Getting posts \" + str(round((index / total_length) * 100)) + \"% completed\")\n",
    "        \n",
    "    return posts_dict\n",
    "\n",
    "\n",
    "# Get the indexes of the posts which do not exist anymore\n",
    "def get_non_exsisting_posts(dataset, posts_dict):\n",
    "    indexes_to_drop = []\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split(\"/\")[-2]\n",
    "        if not shortcode in posts_dict:\n",
    "            indexes_to_drop.append(index)\n",
    "    \n",
    "    return indexes_to_drop\n",
    "            \n",
    "\n",
    "# Delete posts from the dataset based on an array of indexes\n",
    "def del_posts(data, indexes_to_drop):\n",
    "    for index in indexes_to_drop:\n",
    "        data = data.drop(index=index, axis=0)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Enrich dataset with like count\n",
    "def add_like_count_to_dataset(dataset, posts_dict):\n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split(\"/\")[-2]\n",
    "        if shortcode in posts_dict:\n",
    "            dataset.at[index, 'likes count'] = posts_dict[shortcode].likes\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Adds utc date to the dataset\n",
    "def add_date_utc(dataset, posts_dict):\n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split('/')[-2]\n",
    "        if shortcode in posts_dict:\n",
    "            dataset.at[index, 'datum utc'] = posts_dict[shortcode].date_utc\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Refreshes comment count\n",
    "def refresh_comment_count(dataset, posts_dict):\n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split('/')[-2]\n",
    "        if shortcode in posts_dict:\n",
    "            dataset.at[index, 'discussielengte'] = posts_dict[shortcode].comments\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Refreshes view count\n",
    "def refresh_views(dataset, posts_dict):\n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split('/')[-2]\n",
    "        if shortcode in posts_dict:\n",
    "            dataset.at[index, 'views'] = posts_dict[shortcode].likes\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "# Cleans invalid urls and enriches with like count, data utc, comment count and view count\n",
    "def clean_und_enrich(dataset):\n",
    "    posts_dict = get_posts(dataset['url'])\n",
    "    indexes_to_drop = get_non_exsisting_posts(dataset, posts_dict)\n",
    "    dataset = del_posts(dataset, indexes_to_drop)\n",
    "    dataset = add_like_count_to_dataset(dataset, posts_dict)\n",
    "    dataset = add_date_utc(dataset, posts_dict)\n",
    "    dataset = refresh_comment_count(dataset, posts_dict)\n",
    "    dataset = refresh_views(dataset, posts_dict)\n",
    "    \n",
    "    cprint('\\nInvalid urls found: ' + str(len(indexes_to_drop)))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def improve_sentiment(dataset):\n",
    "    dataset['sentiment'] = dataset['sentiment'].replace(np.nan, '0')\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def isolate_hashtag(data):  \n",
    "    total_hashtags = []\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['bericht tekst'] \n",
    "        print(text)\n",
    "        \n",
    "        # find all hashtags in text and isolate them in new column\n",
    "        total_hashtags.append(re.findall(r\"#(\\w+)\", text))\n",
    "        \n",
    "        #remove hashtags from text\n",
    "        pattern = re.compile(\"#(\\w+)\")\n",
    "        newText = pattern.sub(r'', text)\n",
    "        data.at[index, 'bericht tekst'] = newText\n",
    "        \n",
    "    data['hashtags'] = total_hashtags\n",
    "    return data\n",
    "\n",
    "def remove_emoji(data):  \n",
    "    indexes_to_drop = []\n",
    "        \n",
    "    for index, row in data.iterrows():\n",
    "        a = row['bericht tekst']\n",
    "\n",
    "        # todo: vul aan met meer emoji's\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "        newValue = emoji_pattern.sub(r'', a)\n",
    "        newValue = newValue.replace('ü•ó', '')\n",
    "        if newValue == '' : \n",
    "            indexes_to_drop.append(index)\n",
    "            \n",
    "        else:\n",
    "            data.at[index, 'bericht tekst'] = newValue\n",
    "    \n",
    "    pass\n",
    "    data = del_posts(data, indexes_to_drop)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting posts 95% completed\n",
      "Invalid urls found: 2@_korobo_  –∫—Å—Ç–∞—Ç–∏ —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ –∫–æ—Ä–æ–±–æ—á–∫–∏ —Å–Ω–∏–º–∞—Ç—å –≥–æ—Ä–∞–∑–¥–æ —Å–ª–æ–∂–Ω–µ–π.  –Ø –ø—Ä–æ–±–æ–≤–∞–ª–∞ —Å–≤–æ–∏ –æ—Ç—Å–Ω—è—Ç—å. –ù–µ –ø—Ä–æ—Å—Ç–æ, —Ç–∞–∫ —Å–∫–∞–∑–∞—Ç—å....\n",
      "So chic\n",
      "Incredible\n",
      "@divaribas.82 aloe y fibern plus. Escribame 0994895191\n",
      "@remkevet oooh wat goed haha, heerlijk!:)\n",
      "Lovely Japanese copy of Pin Ups. One of my favourites - soon after dark Emily cry's. #vinyljunkie #vinyladdict #welltempered #davidbowie #nowspinning\n",
      "@amanda.carlberg\n",
      "@nobbsy91  look at this!\n",
      "     .......#\n",
      "I can't wait to spend this weekend at #wondercon - - #tbt to Wondercon last year when I ran into @brucewayne626's amazing Armored Batman.\n",
      "Sch√∂nen Abend f√ºr Euch \n",
      "Het programma word steeds slechter!!! Het nieuwe format is al niet om aan te zien, nu ook nog zo dramatische patatbakker als coach? Zonde van het programma #tvoh #notdone\n",
      "Fancy salad  #ski #selfie #luxe #glam #bridal #bossbabe #follow #skier #like #followers #fit #fitgirl #fitnessmodel #fitness #fitspo #fitlife #fitnessaddict #fitnessjourney #gains #gainz #hair #hairstylist #style #fitfam #summer #heat #like4like #haircut #beauty #theknot\n",
      "@teamdavidneres dus dan is hij niet meteen Een prutser hij is beter dan jou\n",
      "En manga larga y estan a 40 grados en madrid @irenedosil\n",
      "@jakenorth03\n",
      "I love you I reel completely grateful to you\n",
      "Wow!\n"
     ]
    }
   ],
   "source": [
    "insta = improve_sentiment(insta)\n",
    "insta = remove_emoji(insta)\n",
    "insta = clean_und_enrich(insta)\n",
    "insta = isolate_hashtag(insta)\n",
    "\n",
    "# Resets index\n",
    "insta.index = range(len(insta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datum</th>\n",
       "      <th>url</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>discussielengte</th>\n",
       "      <th>views</th>\n",
       "      <th>auteur</th>\n",
       "      <th>GPS breedtegraad</th>\n",
       "      <th>GPS lengtegraad</th>\n",
       "      <th>bericht tekst</th>\n",
       "      <th>likes count</th>\n",
       "      <th>datum utc</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-20 17:06</td>\n",
       "      <td>https://instagram.com/p/BVjjp3Cl4uK/</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>marusinalavka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@_korobo_  –∫—Å—Ç–∞—Ç–∏ —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ –∫–æ—Ä–æ–±–æ—á–∫–∏ ...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2017-06-20 09:00:29</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-10 21:43</td>\n",
       "      <td>https://instagram.com/p/BaFFd0fBbcw/</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>artofobservance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So chic</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>2017-10-10 19:36:27</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-28 16:47</td>\n",
       "      <td>https://instagram.com/p/BTbF7AEDgHg/</td>\n",
       "      <td>0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>534004.0</td>\n",
       "      <td>amigabali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incredible</td>\n",
       "      <td>534004.0</td>\n",
       "      <td>2017-04-28 09:03:58</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-04 22:22</td>\n",
       "      <td>https://instagram.com/p/BYoVU-GFypi/</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>gpazminoyepez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@divaribas.82 aloe y fibern plus. Escribame 09...</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>2017-09-04 19:05:41</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-08 10:29</td>\n",
       "      <td>https://instagram.com/p/BbOnSBlFwmo/</td>\n",
       "      <td>+</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>laurienblomphotography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@remkevet oooh wat goed haha, heerlijk!:)</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2017-11-08 08:56:30</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datum                                   url sentiment  \\\n",
       "0  2017-06-20 17:06  https://instagram.com/p/BVjjp3Cl4uK/         0   \n",
       "1  2017-10-10 21:43  https://instagram.com/p/BaFFd0fBbcw/         0   \n",
       "2  2017-04-28 16:47  https://instagram.com/p/BTbF7AEDgHg/         0   \n",
       "3  2017-09-04 22:22  https://instagram.com/p/BYoVU-GFypi/         0   \n",
       "4  2017-11-08 10:29  https://instagram.com/p/BbOnSBlFwmo/         +   \n",
       "\n",
       "   discussielengte     views                  auteur  GPS breedtegraad  \\\n",
       "0              8.0      31.0           marusinalavka               NaN   \n",
       "1             62.0    3639.0         artofobservance               NaN   \n",
       "2           1370.0  534004.0               amigabali               NaN   \n",
       "3             43.0    2224.0           gpazminoyepez               NaN   \n",
       "4             12.0      46.0  laurienblomphotography               NaN   \n",
       "\n",
       "   GPS lengtegraad                                      bericht tekst  \\\n",
       "0              NaN  @_korobo_  –∫—Å—Ç–∞—Ç–∏ —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ –∫–æ—Ä–æ–±–æ—á–∫–∏ ...   \n",
       "1              NaN                                            So chic   \n",
       "2              NaN                                         Incredible   \n",
       "3              NaN  @divaribas.82 aloe y fibern plus. Escribame 09...   \n",
       "4              NaN          @remkevet oooh wat goed haha, heerlijk!:)   \n",
       "\n",
       "   likes count           datum utc hashtags  \n",
       "0         31.0 2017-06-20 09:00:29       []  \n",
       "1       3639.0 2017-10-10 19:36:27       []  \n",
       "2     534004.0 2017-04-28 09:03:58       []  \n",
       "3       2224.0 2017-09-04 19:05:41       []  \n",
       "4         46.0 2017-11-08 08:56:30       []  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output new cleaned dataset\n",
    "data = insta\n",
    "outputCSV(data, \"cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
