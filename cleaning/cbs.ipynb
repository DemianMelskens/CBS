{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "from instaloader import Post\n",
    "import pandas as pd\n",
    "import os\n",
    "import instaloader\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "filepath = '../data/'\n",
    "filename = 'Coosto_berichten2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions    \n",
    "def outputCSV(dataset, filename):\n",
    "    dataset.to_csv(filepath + filename, sep=';')\n",
    "    \n",
    "def cprint(text):\n",
    "    sys.stdout.write(\"\\r\" + text)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datum               22\n",
       "url                 22\n",
       "sentiment            6\n",
       "discussielengte     19\n",
       "views                5\n",
       "auteur              22\n",
       "GPS breedtegraad     2\n",
       "GPS lengtegraad      2\n",
       "bericht tekst       22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve data\n",
    "insta = pd.read_csv(filepath + filename, delimiter=';')\n",
    "\n",
    "# remove empty columns\n",
    "insta = insta.drop(['zoekopdracht', 'type', 'volgers', 'invloed', 'titel', 'type bron'], axis=1)\n",
    "\n",
    "# check with count()\n",
    "insta.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all posts from instagram using an array of urls\n",
    "def get_posts(urls):\n",
    "    posts_dict = {}\n",
    "    total_length = len(urls)\n",
    "    \n",
    "    for index, url in enumerate(urls):\n",
    "        shortcode = url.split(\"/\")[-2]\n",
    "        \n",
    "        try:\n",
    "            L = instaloader.Instaloader()\n",
    "            post = Post.from_shortcode(L.context, url.split(\"/\")[-2])\n",
    "            posts_dict[shortcode] = post\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        cprint(\"Getting posts \" + str(round((index / total_length) * 100)) + \"% completed\")\n",
    "        \n",
    "    return posts_dict\n",
    "\n",
    "\n",
    "# Get the indexes of the posts which do not exist anymore\n",
    "def get_non_exsisting_posts(dataset, posts_dict):\n",
    "    indexes_to_drop = []\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split(\"/\")[-2]\n",
    "        if not shortcode in posts_dict:\n",
    "            indexes_to_drop.append(index)\n",
    "    \n",
    "    return indexes_to_drop\n",
    "            \n",
    "\n",
    "# Delete posts from the dataset based on an array of indexes\n",
    "def del_posts(data, indexes_to_drop):\n",
    "    for index in indexes_to_drop:\n",
    "        data = data.drop(index=index, axis=0)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Enrich dataset with like count\n",
    "def add_like_count_to_dataset(dataset, posts_dict):\n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split(\"/\")[-2]\n",
    "        if shortcode in posts_dict:\n",
    "            dataset.at[index, 'likes count'] = posts_dict[shortcode].likes\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Adds utc date to the dataset\n",
    "def add_date_utc(dataset, posts_dict):\n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split('/')[-2]\n",
    "        if shortcode in posts_dict:\n",
    "            dataset.at[index, 'datum utc'] = posts_dict[shortcode].date_utc\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Refreshes comment count\n",
    "def refresh_comment_count(dataset, posts_dict):\n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split('/')[-2]\n",
    "        if shortcode in posts_dict:\n",
    "            dataset.at[index, 'discussielengte'] = posts_dict[shortcode].comments\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Refreshes view count\n",
    "def refresh_views(dataset, posts_dict):\n",
    "    for index, row in dataset.iterrows():\n",
    "        shortcode = row['url'].split('/')[-2]\n",
    "        if shortcode in posts_dict:\n",
    "            dataset.at[index, 'views'] = posts_dict[shortcode].likes\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "# Cleans invalid urls and enriches with like count, data utc, comment count and view count\n",
    "def clean_und_enrich(dataset):\n",
    "    posts_dict = get_posts(dataset['url'])\n",
    "    indexes_to_drop = get_non_exsisting_posts(dataset, posts_dict)\n",
    "    dataset = del_posts(dataset, indexes_to_drop)\n",
    "    dataset = add_like_count_to_dataset(dataset, posts_dict)\n",
    "    dataset = add_date_utc(dataset, posts_dict)\n",
    "    dataset = refresh_comment_count(dataset, posts_dict)\n",
    "    dataset = refresh_views(dataset, posts_dict)\n",
    "    \n",
    "    cprint('\\nInvalid urls found: ' + str(len(indexes_to_drop)))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def improve_sentiment(dataset):\n",
    "    dataset['sentiment'] = dataset['sentiment'].replace(np.nan, '0')\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def isolate_hashtag(data):  \n",
    "    total_hashtags = []\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['bericht tekst'] \n",
    "        print(text)\n",
    "        \n",
    "        # find all hashtags in text and isolate them in new column\n",
    "        total_hashtags.append(re.findall(r\"#(\\w+)\", text))\n",
    "        \n",
    "        #remove hashtags from text\n",
    "        pattern = re.compile(\"#(\\w+)\")\n",
    "        newText = pattern.sub(r'', text)\n",
    "        data.at[index, 'bericht tekst'] = newText\n",
    "        \n",
    "    data['hashtags'] = total_hashtags\n",
    "    return data\n",
    "\n",
    "def remove_emoji(data):  \n",
    "    indexes_to_drop = []\n",
    "        \n",
    "    for index, row in data.iterrows():\n",
    "        a = row['bericht tekst']\n",
    "\n",
    "        # todo: vul aan met meer emoji's\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "        newValue = emoji_pattern.sub(r'', a)\n",
    "        newValue = newValue.replace('ü•ó', '')\n",
    "        if newValue == '' : \n",
    "            indexes_to_drop.append(index)\n",
    "            \n",
    "        else:\n",
    "            data.at[index, 'bericht tekst'] = newValue\n",
    "    \n",
    "    pass\n",
    "    data = del_posts(data, indexes_to_drop)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting posts 95% completed\n",
      "Invalid urls found: 2@_korobo_  –∫—Å—Ç–∞—Ç–∏ —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ –∫–æ—Ä–æ–±–æ—á–∫–∏ —Å–Ω–∏–º–∞—Ç—å –≥–æ—Ä–∞–∑–¥–æ —Å–ª–æ–∂–Ω–µ–π.  –Ø –ø—Ä–æ–±–æ–≤–∞–ª–∞ —Å–≤–æ–∏ –æ—Ç—Å–Ω—è—Ç—å. –ù–µ –ø—Ä–æ—Å—Ç–æ, —Ç–∞–∫ —Å–∫–∞–∑–∞—Ç—å....\n",
      "So chic\n",
      "Incredible\n",
      "@divaribas.82 aloe y fibern plus. Escribame 0994895191\n",
      "@remkevet oooh wat goed haha, heerlijk!:)\n",
      "Lovely Japanese copy of Pin Ups. One of my favourites - soon after dark Emily cry's. #vinyljunkie #vinyladdict #welltempered #davidbowie #nowspinning\n",
      "@amanda.carlberg\n",
      "@nobbsy91  look at this!\n",
      "     .......#\n",
      "I can't wait to spend this weekend at #wondercon - - #tbt to Wondercon last year when I ran into @brucewayne626's amazing Armored Batman.\n",
      "Sch√∂nen Abend f√ºr Euch \n",
      "Het programma word steeds slechter!!! Het nieuwe format is al niet om aan te zien, nu ook nog zo dramatische patatbakker als coach? Zonde van het programma #tvoh #notdone\n",
      "Fancy salad  #ski #selfie #luxe #glam #bridal #bossbabe #follow #skier #like #followers #fit #fitgirl #fitnessmodel #fitness #fitspo #fitlife #fitnessaddict #fitnessjourney #gains #gainz #hair #hairstylist #style #fitfam #summer #heat #like4like #haircut #beauty #theknot\n",
      "@teamdavidneres dus dan is hij niet meteen Een prutser hij is beter dan jou\n",
      "En manga larga y estan a 40 grados en madrid @irenedosil\n",
      "@jakenorth03\n",
      "I love you I reel completely grateful to you\n",
      "Wow!\n"
     ]
    }
   ],
   "source": [
    "insta = improve_sentiment(insta)\n",
    "insta = remove_emoji(insta)\n",
    "insta = clean_und_enrich(insta)\n",
    "insta = isolate_hashtag(insta)\n",
    "\n",
    "# Resets index\n",
    "insta.index = range(len(insta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datum</th>\n",
       "      <th>url</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>discussielengte</th>\n",
       "      <th>views</th>\n",
       "      <th>auteur</th>\n",
       "      <th>GPS breedtegraad</th>\n",
       "      <th>GPS lengtegraad</th>\n",
       "      <th>bericht tekst</th>\n",
       "      <th>likes count</th>\n",
       "      <th>datum utc</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-20 17:06</td>\n",
       "      <td>https://instagram.com/p/BVjjp3Cl4uK/</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>marusinalavka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@_korobo_  –∫—Å—Ç–∞—Ç–∏ —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ –∫–æ—Ä–æ–±–æ—á–∫–∏ ...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2017-06-20 09:00:29</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-10 21:43</td>\n",
       "      <td>https://instagram.com/p/BaFFd0fBbcw/</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>artofobservance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So chic</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>2017-10-10 19:36:27</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-28 16:47</td>\n",
       "      <td>https://instagram.com/p/BTbF7AEDgHg/</td>\n",
       "      <td>0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>534004.0</td>\n",
       "      <td>amigabali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incredible</td>\n",
       "      <td>534004.0</td>\n",
       "      <td>2017-04-28 09:03:58</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-04 22:22</td>\n",
       "      <td>https://instagram.com/p/BYoVU-GFypi/</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>gpazminoyepez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@divaribas.82 aloe y fibern plus. Escribame 09...</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>2017-09-04 19:05:41</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-08 10:29</td>\n",
       "      <td>https://instagram.com/p/BbOnSBlFwmo/</td>\n",
       "      <td>+</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>laurienblomphotography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@remkevet oooh wat goed haha, heerlijk!:)</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2017-11-08 08:56:30</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-07-20 08:02</td>\n",
       "      <td>https://instagram.com/p/BWwfFxkFoHW/</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>breaking_glass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lovely Japanese copy of Pin Ups. One of my fav...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2017-07-20 06:02:08</td>\n",
       "      <td>[vinyljunkie, vinyladdict, welltempered, david...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-02-10 22:27</td>\n",
       "      <td>https://instagram.com/p/Bdp4B0Pj6TL/</td>\n",
       "      <td>0</td>\n",
       "      <td>9411.0</td>\n",
       "      <td>223473.0</td>\n",
       "      <td>belmacurkicc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@amanda.carlberg</td>\n",
       "      <td>223473.0</td>\n",
       "      <td>2018-01-07 16:05:07</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-02-21 18:01</td>\n",
       "      <td>https://instagram.com/p/BfdzxFYlj-h/</td>\n",
       "      <td>+</td>\n",
       "      <td>699.0</td>\n",
       "      <td>103847.0</td>\n",
       "      <td>_lilysmith97_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@nobbsy91  look at this!</td>\n",
       "      <td>103847.0</td>\n",
       "      <td>2018-02-21 16:39:47</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-08-28 17:40</td>\n",
       "      <td>https://instagram.com/p/BYVy0NRBGdr/</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>heimint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.......#</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2017-08-28 14:17:47</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-03-30 22:45</td>\n",
       "      <td>https://instagram.com/p/BSRrHmbDSui/</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>bsunphotography</td>\n",
       "      <td>34.041531</td>\n",
       "      <td>-118.269028</td>\n",
       "      <td>I can't wait to spend this weekend at  - -  to...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2017-03-30 20:45:12</td>\n",
       "      <td>[wondercon, tbt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-06-07 21:16</td>\n",
       "      <td>https://instagram.com/p/BVDLFfaFllE/</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>minimemalzwei</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sch√∂nen Abend f√ºr Euch</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2017-06-07 19:10:07</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-02-17 00:23</td>\n",
       "      <td>https://instagram.com/p/BfRhTsqjm6w/</td>\n",
       "      <td>-</td>\n",
       "      <td>188.0</td>\n",
       "      <td>3910.0</td>\n",
       "      <td>andynuberg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Het programma word steeds slechter!!! Het nieu...</td>\n",
       "      <td>3910.0</td>\n",
       "      <td>2018-02-16 22:07:36</td>\n",
       "      <td>[tvoh, notdone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-05 23:19</td>\n",
       "      <td>https://instagram.com/p/BdlZSuUAd6B/</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>chocolatealldayeveryday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fancy salad</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2018-01-05 22:19:35</td>\n",
       "      <td>[ski, selfie, luxe, glam, bridal, bossbabe, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-02-10 13:05</td>\n",
       "      <td>https://instagram.com/p/BQVHc0QAqTd/</td>\n",
       "      <td>-</td>\n",
       "      <td>6.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>arberzenelifans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@teamdavidneres dus dan is hij niet meteen Een...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2017-02-10 11:47:42</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-07-12 19:48</td>\n",
       "      <td>https://instagram.com/p/BWdITU8hZ9Q/</td>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>7167.0</td>\n",
       "      <td>martammoreda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>En manga larga y estan a 40 grados en madrid @...</td>\n",
       "      <td>7167.0</td>\n",
       "      <td>2017-07-12 17:37:26</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-12-28 01:20</td>\n",
       "      <td>https://instagram.com/p/BdMzeXkjvHW/</td>\n",
       "      <td>0</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>291417.0</td>\n",
       "      <td>joshrudolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jakenorth03</td>\n",
       "      <td>291417.0</td>\n",
       "      <td>2017-12-27 09:07:51</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-01-07 23:11</td>\n",
       "      <td>https://instagram.com/p/BM4jI_3g7a2/</td>\n",
       "      <td>0</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>965387.0</td>\n",
       "      <td>bertem17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love you I reel completely grateful to you</td>\n",
       "      <td>965387.0</td>\n",
       "      <td>2016-11-16 19:57:30</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-08-23 12:42</td>\n",
       "      <td>https://instagram.com/p/BYIOeycFiWq/</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>ucademycollege</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wow!</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2017-08-23 07:50:10</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datum                                   url sentiment  \\\n",
       "0   2017-06-20 17:06  https://instagram.com/p/BVjjp3Cl4uK/         0   \n",
       "1   2017-10-10 21:43  https://instagram.com/p/BaFFd0fBbcw/         0   \n",
       "2   2017-04-28 16:47  https://instagram.com/p/BTbF7AEDgHg/         0   \n",
       "3   2017-09-04 22:22  https://instagram.com/p/BYoVU-GFypi/         0   \n",
       "4   2017-11-08 10:29  https://instagram.com/p/BbOnSBlFwmo/         +   \n",
       "5   2017-07-20 08:02  https://instagram.com/p/BWwfFxkFoHW/         0   \n",
       "6   2018-02-10 22:27  https://instagram.com/p/Bdp4B0Pj6TL/         0   \n",
       "7   2018-02-21 18:01  https://instagram.com/p/BfdzxFYlj-h/         +   \n",
       "8   2017-08-28 17:40  https://instagram.com/p/BYVy0NRBGdr/         0   \n",
       "9   2017-03-30 22:45  https://instagram.com/p/BSRrHmbDSui/         0   \n",
       "10  2017-06-07 21:16  https://instagram.com/p/BVDLFfaFllE/         0   \n",
       "11  2018-02-17 00:23  https://instagram.com/p/BfRhTsqjm6w/         -   \n",
       "12  2018-01-05 23:19  https://instagram.com/p/BdlZSuUAd6B/         0   \n",
       "13  2017-02-10 13:05  https://instagram.com/p/BQVHc0QAqTd/         -   \n",
       "14  2017-07-12 19:48  https://instagram.com/p/BWdITU8hZ9Q/         0   \n",
       "15  2017-12-28 01:20  https://instagram.com/p/BdMzeXkjvHW/         0   \n",
       "16  2017-01-07 23:11  https://instagram.com/p/BM4jI_3g7a2/         0   \n",
       "17  2017-08-23 12:42  https://instagram.com/p/BYIOeycFiWq/         0   \n",
       "\n",
       "    discussielengte     views                   auteur  GPS breedtegraad  \\\n",
       "0               8.0      31.0            marusinalavka               NaN   \n",
       "1              62.0    3639.0          artofobservance               NaN   \n",
       "2            1370.0  534004.0                amigabali               NaN   \n",
       "3              43.0    2224.0            gpazminoyepez               NaN   \n",
       "4              12.0      46.0   laurienblomphotography               NaN   \n",
       "5               0.0      63.0           breaking_glass               NaN   \n",
       "6            9411.0  223473.0             belmacurkicc               NaN   \n",
       "7             699.0  103847.0            _lilysmith97_               NaN   \n",
       "8               2.0      17.0                  heimint               NaN   \n",
       "9               9.0      91.0          bsunphotography         34.041531   \n",
       "10              9.0      84.0            minimemalzwei               NaN   \n",
       "11            188.0    3910.0               andynuberg               NaN   \n",
       "12              2.0      48.0  chocolatealldayeveryday               NaN   \n",
       "13              6.0     178.0          arberzenelifans               NaN   \n",
       "14             94.0    7167.0             martammoreda               NaN   \n",
       "15           1463.0  291417.0               joshrudolf               NaN   \n",
       "16           5158.0  965387.0                 bertem17               NaN   \n",
       "17              3.0      87.0           ucademycollege               NaN   \n",
       "\n",
       "    GPS lengtegraad                                      bericht tekst  \\\n",
       "0               NaN  @_korobo_  –∫—Å—Ç–∞—Ç–∏ —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ –∫–æ—Ä–æ–±–æ—á–∫–∏ ...   \n",
       "1               NaN                                            So chic   \n",
       "2               NaN                                         Incredible   \n",
       "3               NaN  @divaribas.82 aloe y fibern plus. Escribame 09...   \n",
       "4               NaN          @remkevet oooh wat goed haha, heerlijk!:)   \n",
       "5               NaN  Lovely Japanese copy of Pin Ups. One of my fav...   \n",
       "6               NaN                                   @amanda.carlberg   \n",
       "7               NaN                           @nobbsy91  look at this!   \n",
       "8               NaN                                           .......#   \n",
       "9       -118.269028  I can't wait to spend this weekend at  - -  to...   \n",
       "10              NaN                            Sch√∂nen Abend f√ºr Euch    \n",
       "11              NaN  Het programma word steeds slechter!!! Het nieu...   \n",
       "12              NaN         Fancy salad                                  \n",
       "13              NaN  @teamdavidneres dus dan is hij niet meteen Een...   \n",
       "14              NaN  En manga larga y estan a 40 grados en madrid @...   \n",
       "15              NaN                                       @jakenorth03   \n",
       "16              NaN       I love you I reel completely grateful to you   \n",
       "17              NaN                                               Wow!   \n",
       "\n",
       "    likes count           datum utc  \\\n",
       "0          31.0 2017-06-20 09:00:29   \n",
       "1        3639.0 2017-10-10 19:36:27   \n",
       "2      534004.0 2017-04-28 09:03:58   \n",
       "3        2224.0 2017-09-04 19:05:41   \n",
       "4          46.0 2017-11-08 08:56:30   \n",
       "5          63.0 2017-07-20 06:02:08   \n",
       "6      223473.0 2018-01-07 16:05:07   \n",
       "7      103847.0 2018-02-21 16:39:47   \n",
       "8          17.0 2017-08-28 14:17:47   \n",
       "9          91.0 2017-03-30 20:45:12   \n",
       "10         84.0 2017-06-07 19:10:07   \n",
       "11       3910.0 2018-02-16 22:07:36   \n",
       "12         48.0 2018-01-05 22:19:35   \n",
       "13        178.0 2017-02-10 11:47:42   \n",
       "14       7167.0 2017-07-12 17:37:26   \n",
       "15     291417.0 2017-12-27 09:07:51   \n",
       "16     965387.0 2016-11-16 19:57:30   \n",
       "17         87.0 2017-08-23 07:50:10   \n",
       "\n",
       "                                             hashtags  \n",
       "0                                                  []  \n",
       "1                                                  []  \n",
       "2                                                  []  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "5   [vinyljunkie, vinyladdict, welltempered, david...  \n",
       "6                                                  []  \n",
       "7                                                  []  \n",
       "8                                                  []  \n",
       "9                                    [wondercon, tbt]  \n",
       "10                                                 []  \n",
       "11                                    [tvoh, notdone]  \n",
       "12  [ski, selfie, luxe, glam, bridal, bossbabe, fo...  \n",
       "13                                                 []  \n",
       "14                                                 []  \n",
       "15                                                 []  \n",
       "16                                                 []  \n",
       "17                                                 []  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insta.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output new cleaned dataset\n",
    "data = insta\n",
    "outputCSV(data, \"cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 2500\n",
    "made_files = 0\n",
    "\n",
    "def split_file(made_files):\n",
    "    for i,chunk in enumerate(pd.read_csv(filepath + filename, delimiter=';', chunksize=chunksize)):\n",
    "        chunk = chunk.drop(['zoekopdracht', 'type', 'volgers', 'invloed', 'titel', 'type bron'], axis=1)\n",
    "        chunk.to_csv(filepath + 'set{}.csv'.format(i), sep=';')\n",
    "        made_files +=1\n",
    "    return made_files\n",
    "\n",
    "made_files = split_file(made_files)\n",
    "print(made_files)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning al data files after another\n",
    "def clean_splitted_files():\n",
    "    for num in range(0, made_files):\n",
    "        setfile = pd.read_csv(filepath + \"set\"+ str(num) + '.csv', delimiter=';')\n",
    "\n",
    "        setfile = improve_sentiment(setfile)\n",
    "        setfile = remove_emoji(setfile)\n",
    "        setfile = clean_und_enrich(setfile)\n",
    "        setfile = isolate_hashtag(setfile)\n",
    "\n",
    "        # Resets index\n",
    "        outputCSV(setfile,\"set\"+ str(num) + '.csv')\n",
    "\n",
    "clean_splitted_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mergin all all datafile in one file\n",
    "def merge_splitted_files_to_one:\n",
    "    merged_filename = \"merged_file.csv\"\n",
    "    try:\n",
    "        os.remove(filepath + merged_filename)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    outputfile = open(filepath + merged_filename, \"a\", encoding=\"utf8\")\n",
    "    for line in open(filepath + \"set0.csv\", encoding=\"utf8\"):\n",
    "        outputfile.write(line)\n",
    "    # now the rest:    \n",
    "    for num in range(1,made_files):\n",
    "        setfile = open(filepath +\"set\"+ str(num) +\".csv\", encoding=\"utf8\")\n",
    "        setfile.__next__() # skip the header\n",
    "        for line in setfile:\n",
    "             outputfile.write(line)\n",
    "        setfile.close() # not really needed\n",
    "    outputfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
