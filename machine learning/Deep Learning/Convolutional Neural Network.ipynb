{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "make sure you have acces to the keras and tensorflow packages\n",
    "```pip install keras``` & ```pip install tensorflow```\n",
    "\n",
    "A Convolutional neural network is mainly used to categorize images. by copying the behavoir of the brain. the layers are capable of extracting features from images. CNN's have two components:\n",
    "1. The hidden layers / feature extraction\n",
    "2. The Classification layers\n",
    "\n",
    "<img src=\"./images/architecture.png\">\n",
    "\n",
    "### Sources\n",
    "[https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050](https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050)\n",
    "\n",
    "[https://keras.io/layers/convolutional/#conv2d](https://keras.io/layers/convolutional/#conv2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_classes = 10\n",
    "\n",
    "# Setup the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden layers / Feature extraction\n",
    "## Conv2D Layer\n",
    "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If ```use_bias``` is True, a bias vector is created and added to the outputs. Finally, if ```activation``` is not ```None```, it is applied to the outputs as well.\n",
    "\n",
    "When using this layer as the first layer in a model, provide the keyword argument  \n",
    "```input_shape ``` (tuple of integers, does not include the sample axis), e.g.  \n",
    "```input_shape=(128, 128, 3)``` for 128x128 RGB pictures in  \n",
    "```data_format=\"channels_last\".```\n",
    "\n",
    "### Arguments\n",
    "* __filters__: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "* __kernel_size__: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "* __strides__: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any ```dilation_rate``` value != 1.\n",
    "* __padding__: one of ```\"valid\"``` or ```\"same\"``` (case-insensitive). Note that ```\"same\"``` is slightly inconsistent across backends with  strides != 1.\n",
    "* __data_format__: A string, one of ```\"channels_last\"``` or ```\"channels_first\"```. The ordering of the dimensions in the inputs.  ```\"channels_last\"``` corresponds to inputs with shape ```(batch, height, width, channels)``` while  ```\"channels_first\"``` corresponds to inputs with shape ```(batch, channels, height, width)```. It defaults to the  ```image_data_format``` value found in your Keras config file at ```~/.keras/keras.json.``` If you never set it, then it will be \"channels_last\".\n",
    "* __dilation_rate__: an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any ```dilation_rate value``` != 1 is incompatible with specifying any stride value != 1.\n",
    "* __activation__: Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: ```a(x) = x```).\n",
    "* __use_bias__: Boolean, whether the layer uses a bias vector.\n",
    "* __kernel_initializer__: Initializer for the ```kernel``` weights matrix.\n",
    "* __bias_initializer__: Initializer for the bias vector.\n",
    "* __kernel_regularizer__: Regularizer function applied to the ```kernel``` weights matrix.\n",
    "* __bias_regularizer__: Regularizer function applied to the bias vector.\n",
    "* __activity_regularizer__: Regularizer function applied to the output of the layer (its \"activation\").\n",
    "* __kernel_constraint__: Constraint function applied to the kernel matrix.\n",
    "* __bias_constraint__: Constraint function applied to the bias vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images fed into this model are 512x512 pixels with 3 channels (RGB)\n",
    "image_input_shape  = (512,512,3)\n",
    "\n",
    "# Add convolutional layer with 3x3x3 filter 32 times and a stride size of 1\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=image_input_shape,padding='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Layer _(ReLU Layer)_\n",
    "\n",
    "Rectified Linear Unit.\n",
    "\n",
    "With default values, it returns element-wise ```max(x, 0)```.\n",
    "\n",
    "Otherwise, it follows: ```f(x) = max_value``` for ```x >= max_value```, ```f(x) = x``` for ```threshold <= x < max_value, f(x) = alpha * (x - threshold)``` otherwise.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "* __activation__: name of activation function to use, or alternatively, a Theano or TensorFlow operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relu activation to the layer \n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "\n",
    "Max pooling operation for spatial data.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "* __pool_size__: integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.\n",
    "* __strides__: Integer, tuple of 2 integers, or None. Strides values. If None, it will default to ```pool_size```.\n",
    "* __padding__: One of ```\"valid\"``` or ```\"same\"``` (case-insensitive).\n",
    "* __data_format__: A string, one of ```channels_last``` (default) or ```channels_first```. The ordering of the dimensions in the inputs.  ```channels_last``` corresponds to inputs with shape  ```(batch, height, width, channels)``` while ```channels_first``` corresponds to inputs with shape  ```(batch, channels, height, width)```. It defaults to the  ```image_data_format``` value found in your Keras config file at ```~/.keras/keras.json```. If you never set it, then it will be \"channels_last\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling\n",
    "model.add(MaxPooling2D(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Layers\n",
    "## Flatten Layer\n",
    "\n",
    "Flattens the input. Does not affect the batch size.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "* __data_format__: A string, one of ```channels_last``` (default) or ```channels_first```. The ordering of the dimensions in the inputs. The purpose of this argument is to preserve weight ordering when switching a model from one data format to another.  ```channels_last``` corresponds to inputs with shape  ```(batch, ..., channels)``` while  ```channels_first``` corresponds to inputs with shape ```(batch, channels, ...)```. It defaults to the ```image_data_format``` value found in your Keras config file at  ```~/.keras/keras.json```. If you never set it, then it will be \"channels_last\".\n",
    "\n",
    "### Example\n",
    "\n",
    "```Python\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3),\n",
    "                 input_shape=(3, 32, 32), padding='same',))\n",
    "# now: model.output_shape == (None, 64, 32, 32)\n",
    "\n",
    "model.add(Flatten())\n",
    "# now: model.output_shape == (None, 65536)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Flatten to convert 3D data to 1D\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Layers\n",
    "\n",
    "Just your regular densely-connected NN layer.\n",
    "\n",
    "```Dense``` implements the operation: ```output = activation(dot(input, kernel) + bias)``` where ```activation``` is the element-wise activation function passed as the ```activation``` argument, ```kernel``` is a weights matrix created by the layer, and ```bias``` is a bias vector created by the layer (only applicable if ```use_bias``` is ```True```).\n",
    "\n",
    "Note: if the input to the layer has a rank greater than 2, then it is flattened prior to the initial dot product with ```kernel```.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "* __units__: Positive integer, dimensionality of the output space.\n",
    "* __activation__: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. \"linear\" activation: ```a(x) = x)```.\n",
    "* __use_bias__: Boolean, whether the layer uses a bias vector.\n",
    "* __kernel_initializer__: Initializer for the ```kernel``` weights matrix.\n",
    "* __bias_initializer__: Initializer for the bias vector.\n",
    "* __kernel_regularizer__: Regularizer function applied to the ```kernel``` weights matrix.\n",
    "* __bias_regularizer__: Regularizer function applied to the bias vector.\n",
    "* __activity_regularizer__: Regularizer function applied to the output of the layer (its \"activation\").\n",
    "* __kernel_constraint__: Constraint function applied to the ```kernel``` weights matrix.\n",
    "* __bias_constraint__: Constraint function applied to the bias vector.\n",
    "\n",
    "### Example\n",
    "```Python\n",
    "# as first layer in a sequential model:\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(16,)))\n",
    "# now the model will take as input arrays of shape (*, 16)\n",
    "# and output arrays of shape (*, 32)\n",
    "\n",
    "# after the first layer, you don't need to specify\n",
    "# the size of the input anymore:\n",
    "model.add(Dense(32))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dense layer with 10 neurons\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Layer (Softmax Layer)\n",
    "\n",
    "Softmax activation function.\n",
    "\n",
    "produces just the result of applying the softmax function to an input tensor. The softmax \"squishes\" the inputs so that ```sum(input) = 1;``` it's a way of normalizing. The shape of output of a softmax is the same as the input - it just normalizes the values. The outputs of softmax can be interpreted as probabilities.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "* __activation__: name of activation function to use, or alternatively, a Theano or TensorFlow operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the softmax activation function for our last layer\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 512, 512, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512, 512, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2097152)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20971530  \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 20,972,426\n",
      "Trainable params: 20,972,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# give an overview of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Training a CNN works in the same way as a regular neural network, using backpropagration or gradient descent. However, here this is a bit more mathematically complex because of the convolution operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before the training process, we have to put together a learning process in a particular form. \n",
    "# It consists of 3 elements: an optimiser, a loss function and a metric.\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
